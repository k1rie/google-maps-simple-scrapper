# Scraper de Google Maps - API

API backend con Express y Puppeteer para extraer informaci√≥n completa de negocios (nombre, tel√©fono, direcci√≥n, calificaci√≥n, etc.) de los resultados de b√∫squeda en Google Maps. Incluye opci√≥n para descargar los resultados en formato CSV.

## üöÄ Instalaci√≥n

```bash
npm install
```

## üì¶ Dependencias

- **express**: Framework web para Node.js
- **puppeteer**: Librer√≠a para automatizar navegador (Chrome/Chromium)
- **nodemon**: Herramienta para desarrollo con auto-reload
- **cors**: Middleware para habilitar CORS

## üèÉ Uso

### Modo desarrollo (con nodemon):
```bash
npm run dev
```

### Modo producci√≥n:
```bash
npm start
```

El servidor se iniciar√° en `http://localhost:3000`

## üê≥ Docker

### Construir y ejecutar con Docker:

```bash
# Construir la imagen
docker build -t scrapper-maps .

# Ejecutar el contenedor
docker run -d -p 3000:3000 --name scrapper-maps scrapper-maps
```

### Usar Docker Compose:

```bash
# Construir y ejecutar
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener
docker-compose down
```

El servidor estar√° disponible en `http://localhost:3000`

## üì° Endpoints

### GET /scrape
Extrae informaci√≥n completa de negocios de una b√∫squeda en Google Maps.

**Par√°metros:**
- `query` o `search`: Texto a buscar en Google Maps
- `format` (opcional): Si es `csv` o `CSV`, descarga los resultados en formato CSV

**Ejemplos:**

**Obtener resultados en JSON:**
```bash
curl "http://localhost:3000/scrape?query=medicos%20especialistas%20en%20chiapas"
```

**Descargar resultados en CSV:**
```bash
curl "http://localhost:3000/scrape?query=medicos%20especialistas%20en%20chiapas&format=csv" -o negocios.csv
```

### POST /scrape
Mismo endpoint pero acepta par√°metros en el body.

**Ejemplos:**

**Obtener resultados en JSON:**
```bash
curl -X POST http://localhost:3000/scrape \
  -H "Content-Type: application/json" \
  -d '{"query": "medicos especialistas en chiapas"}'
```

**Descargar resultados en CSV:**
```bash
curl -X POST http://localhost:3000/scrape \
  -H "Content-Type: application/json" \
  -d '{"query": "medicos especialistas en chiapas", "format": "csv"}' \
  -o negocios.csv
```

### GET /health
Endpoint de salud para verificar que el servidor est√° funcionando.

## üìã Respuesta

### Formato JSON (por defecto)

```json
{
  "success": true,
  "query": "medicos especialistas en chiapas",
  "totalNegocios": 15,
  "negocios": [
    {
      "nombre": "Dr. Juan P√©rez - Especialista en Cardiolog√≠a",
      "telefono": "961 930 0214",
      "direccion": "Av. Central 123, Tuxtla Guti√©rrez, Chiapas",
      "calificacion": "4.5",
      "rese√±as": "120",
      "categoria": "M√©dico especialista"
    },
    {
      "nombre": "Cl√≠nica M√©dica San Jos√©",
      "telefono": "961 453 1050",
      "direccion": "Calle 5 de Mayo 456, Chiapas",
      "calificacion": "4.8",
      "rese√±as": "85",
      "categoria": "Cl√≠nica m√©dica"
    },
    ...
  ]
}
```

### Formato CSV

Cuando se usa el par√°metro `format=csv`, la respuesta es un archivo CSV descargable con las siguientes columnas:
- nombre
- telefono
- direccion
- calificacion
- rese√±as
- categoria

El archivo incluye BOM UTF-8 para compatibilidad con Excel.

## üìÅ Estructura del Proyecto

```
scrapper-maps/
‚îú‚îÄ‚îÄ controllers/          # Controladores (l√≥gica de negocio)
‚îÇ   ‚îî‚îÄ‚îÄ scrapeController.js
‚îú‚îÄ‚îÄ routes/              # Rutas de la API
‚îÇ   ‚îú‚îÄ‚îÄ scrapeRoutes.js
‚îÇ   ‚îî‚îÄ‚îÄ healthRoutes.js
‚îú‚îÄ‚îÄ services/            # Servicios (l√≥gica de scraping)
‚îÇ   ‚îî‚îÄ‚îÄ scraperService.js
‚îú‚îÄ‚îÄ server.js            # Punto de entrada de la aplicaci√≥n
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
```

## ‚öôÔ∏è Caracter√≠sticas

- ‚úÖ Arquitectura MVC con separaci√≥n de responsabilidades
- ‚úÖ Scraping autom√°tico con Puppeteer (navegador headless)
- ‚úÖ Scroll autom√°tico hasta encontrar todos los resultados
- ‚úÖ Detecci√≥n del mensaje "No hay m√°s resultados"
- ‚úÖ Extracci√≥n completa de informaci√≥n de negocios:
  - Nombre del negocio
  - N√∫mero de tel√©fono
  - Direcci√≥n
  - Calificaci√≥n
  - N√∫mero de rese√±as
  - Categor√≠a/tipo de negocio
- ‚úÖ Eliminaci√≥n de duplicados por nombre
- ‚úÖ Soporte para formatos mexicanos e internacionales de tel√©fono
- ‚úÖ Exportaci√≥n a CSV con un solo par√°metro
- ‚úÖ Manejo de errores robusto

## üîß Configuraci√≥n

El puerto puede configurarse mediante la variable de entorno `PORT`:

```bash
PORT=4000 npm start
```

## üîç Verificaci√≥n de Instalaci√≥n

Para verificar que Puppeteer est√° instalado correctamente:

```bash
npm run check
```

Este comando verifica que el navegador pueda lanzarse correctamente.

## üõ†Ô∏è Soluci√≥n de Problemas

### Error: "Failed to launch the browser process" en macOS

**Este es un problema conocido en macOS**, especialmente en versiones recientes. Los warnings sobre "unexpected crash info version 7" son normales y no cr√≠ticos.

**‚úÖ Soluci√≥n autom√°tica:**
El c√≥digo ahora detecta autom√°ticamente si Chrome est√° instalado en macOS y lo usa. Si tienes Chrome instalado, deber√≠a funcionar sin configuraci√≥n adicional.

**Si a√∫n tienes problemas:**

1. **Dar permisos de accesibilidad a Terminal/Node:**
   - Ve a: **Preferencias del Sistema** ‚Üí **Seguridad y Privacidad** ‚Üí **Privacidad** ‚Üí **Accesibilidad**
   - Aseg√∫rate de que Terminal (o tu IDE) tenga permisos

2. **Verificar que Chrome est√° instalado:**
   ```bash
   ls -la "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
   ```

### üöÄ Producci√≥n (Railway/Linux)

**¬°Buenas noticias!** En producci√≥n **NO tendr√°s este problema** porque:

- ‚úÖ Railway usa **Linux**, no macOS
- ‚úÖ Puppeteer funciona **perfectamente** en Linux
- ‚úÖ No hay problemas de permisos como en macOS
- ‚úÖ El c√≥digo detecta autom√°ticamente el entorno y usa la configuraci√≥n correcta
- ‚úÖ Chromium se descarga autom√°ticamente durante el build

**No necesitas hacer nada especial para producci√≥n.** El c√≥digo ya est√° configurado para:
- **Desarrollo (macOS)**: Usa Chrome del sistema si est√° disponible
- **Producci√≥n (Linux)**: Usa Chromium de Puppeteer autom√°ticamente

**Otras soluciones:**

1. **Verificar que Chromium se descarg√≥:**
   ```bash
   ls -la node_modules/puppeteer/.local-chromium/
   ```
   Si est√° vac√≠o, forzar descarga:
   ```bash
   rm -rf node_modules/puppeteer/.local-chromium
   PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=false npm install puppeteer --force
   ```

2. **En macOS, verificar herramientas de desarrollo:**
   ```bash
   xcode-select --install
   ```
   Si ya est√° instalado, verificar:
   ```bash
   xcode-select -p
   ```

3. **Problemas con Rosetta (Mac con Apple Silicon):**
   Si est√°s en una Mac con Apple Silicon y Node.js est√° ejecut√°ndose bajo Rosetta:
   ```bash
   # Verificar arquitectura
   uname -m
   node -p "process.arch"
   ```
   Aseg√∫rate de que ambos coincidan.

4. **Usar Chrome instalado en el sistema (alternativa):**
   Si tienes Chrome instalado, puedes configurar Puppeteer para usarlo:
   ```bash
   # En macOS, Chrome generalmente est√° en:
   # /Applications/Google Chrome.app/Contents/MacOS/Google Chrome
   ```
   Luego modifica `services/scraperService.js` para usar:
   ```javascript
   executablePath: '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
   ```

5. **Reinstalar completamente:**
   ```bash
   rm -rf node_modules package-lock.json
   npm install
   npm install puppeteer --force
   ```

6. **Verificar instalaci√≥n:**
   ```bash
   npm run check
   ```

### Error: "ECONNRESET" o errores de conexi√≥n

Estos errores son comunes y el scraper los maneja autom√°ticamente. Si se extraen n√∫meros antes del error, se retornan en la respuesta.

## ‚ö†Ô∏è Notas

- El scraper hace scroll autom√°ticamente hasta encontrar todos los resultados
- Se detiene cuando aparece el mensaje "No hay m√°s resultados"
- Los n√∫meros de tel√©fono se extraen de m√∫ltiples fuentes en el DOM
- El proceso puede tardar varios segundos dependiendo de la cantidad de resultados
- El scraper usa el nuevo modo headless de Chrome para mejor rendimiento

# google-maps-simple-scrapper
# google-maps-simple-scrapper
# google-maps-simple-scrapper
